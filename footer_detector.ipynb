{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodjonSobiani/ml_learning/blob/main/footer_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTELqwXy_U9G",
        "outputId": "a5271801-caae-4958-f641-8f436a3ebc30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwpy57u-rJkZ",
        "outputId": "c3308355-3b19-4c20-e32a-d30f5b46dca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NljTk9Q-zh9"
      },
      "outputs": [],
      "source": [
        "!pip install -r '/content/drive/MyDrive/Mask-RCNN-TF2/requirements.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk_9bq4DlqqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779b6ffb-63f8-428b-a427-9793e878ae6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 6710839765108788735\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 11661897060180353958\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8775625942144034676\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14949928141\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 7669517779383052029\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5lwsa3lmm4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99bc51a-c00b-477a-d626-2f056e677c2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.4 GB  | Proc size: 500.4 MB\n",
            "GPU RAM Free: 15005MB | Used: 104MB | Util   1% | Total 15109MB\n"
          ]
        }
      ],
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnt guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOJdz-wTuST3",
        "outputId": "c0e85b37-e73f-488d-f3ab-34da4a656974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "Weights:  coco\n",
            "Dataset:  /content/drive/MyDrive/Mask-RCNN-TF2/dataset/footer\n",
            "Logs:  /content/drive/MyDrive/Mask-RCNN-TF2/logs\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     1\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.75\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 1\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                20\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           form_login\n",
            "NUM_CLASSES                    8\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                200\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "Loading weights  /content/drive/MyDrive/Mask-RCNN-TF2/mask_rcnn_coco.h5\n",
            "manual annotation class count: 7\n",
            "annotations count:\t239\n",
            "manual annotation class count: 7\n",
            "annotations count:\t60\n",
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: //logdir//train/mask_rcnn_form_login_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... can't pickle _thread.RLock objects\n",
            "Epoch 1/25\n",
            "  2/200 [..............................] - ETA: 1:10:36 - loss: 13.41112022-07-03 06:09:07.522525: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.\n",
            "200/200 [==============================] - 288s 1s/step - loss: 3.3774 - val_loss: 1.9504\n",
            "Epoch 2/25\n",
            "200/200 [==============================] - 207s 1s/step - loss: 2.2661 - val_loss: 1.9219\n",
            "Epoch 3/25\n",
            "200/200 [==============================] - 223s 1s/step - loss: 2.1284 - val_loss: 2.3726\n",
            "Epoch 4/25\n",
            "200/200 [==============================] - 209s 1s/step - loss: 2.0890 - val_loss: 2.0281\n",
            "Epoch 5/25\n",
            "200/200 [==============================] - 223s 1s/step - loss: 1.9114 - val_loss: 2.2176\n",
            "Epoch 6/25\n",
            "200/200 [==============================] - 206s 1s/step - loss: 1.8949 - val_loss: 1.6222\n",
            "Epoch 7/25\n",
            "200/200 [==============================] - 212s 1s/step - loss: 1.8572 - val_loss: 1.6915\n",
            "Epoch 8/25\n",
            "200/200 [==============================] - 210s 1s/step - loss: 1.7013 - val_loss: 9.8811\n",
            "Epoch 9/25\n",
            "200/200 [==============================] - 216s 1s/step - loss: 1.9814 - val_loss: 1.9944\n",
            "Epoch 10/25\n",
            "200/200 [==============================] - 218s 1s/step - loss: 1.7449 - val_loss: 2.5791\n",
            "Epoch 11/25\n",
            "200/200 [==============================] - 227s 1s/step - loss: 1.8179 - val_loss: 2.0504\n",
            "Epoch 12/25\n",
            "200/200 [==============================] - 206s 1s/step - loss: 1.5850 - val_loss: 1.7629\n",
            "Epoch 13/25\n",
            "200/200 [==============================] - 226s 1s/step - loss: 1.4690 - val_loss: 1.4136\n",
            "Epoch 14/25\n",
            "200/200 [==============================] - 212s 1s/step - loss: 1.7499 - val_loss: 1.1386\n",
            "Epoch 15/25\n",
            "200/200 [==============================] - 213s 1s/step - loss: 1.5368 - val_loss: 1.6600\n",
            "Epoch 16/25\n",
            "200/200 [==============================] - 221s 1s/step - loss: 1.6560 - val_loss: 2.4620\n",
            "Epoch 17/25\n",
            "200/200 [==============================] - 208s 1s/step - loss: 1.6028 - val_loss: 2.0078\n",
            "Epoch 18/25\n",
            "200/200 [==============================] - 223s 1s/step - loss: 1.5085 - val_loss: 1.8064\n",
            "Epoch 19/25\n",
            "200/200 [==============================] - 212s 1s/step - loss: 1.4480 - val_loss: 1.4253\n",
            "Epoch 20/25\n",
            "200/200 [==============================] - 225s 1s/step - loss: 1.4559 - val_loss: 1.6749\n",
            "Epoch 21/25\n",
            "200/200 [==============================] - 208s 1s/step - loss: 1.3776 - val_loss: 4.4410\n",
            "Epoch 22/25\n",
            "200/200 [==============================] - 208s 1s/step - loss: 1.5116 - val_loss: 2.5641\n",
            "Epoch 23/25\n",
            "200/200 [==============================] - 216s 1s/step - loss: 1.4111 - val_loss: 1.8316\n",
            "Epoch 24/25\n",
            "200/200 [==============================] - 223s 1s/step - loss: 1.2767 - val_loss: 1.8170\n",
            "Epoch 25/25\n",
            "200/200 [==============================] - 206s 1s/step - loss: 1.3409 - val_loss: 2.3566\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/drive/MyDrive/Mask-RCNN-TF2/samples/footer/footer.py train --dataset=/content/drive/MyDrive/Mask-RCNN-TF2/dataset/footer --weights=coco"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/drive/MyDrive/Mask-RCNN-TF2/samples/footer/footer.py train --dataset=/content/drive/MyDrive/Mask-RCNN-TF2/dataset/footer --weights=coco"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvKGk-4TGcmv",
        "outputId": "51cc1a7f-977a-4ad0-9798-7060b89a2154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "Weights:  coco\n",
            "Dataset:  /content/drive/MyDrive/Mask-RCNN-TF2/dataset/footer\n",
            "Logs:  /content/drive/MyDrive/Mask-RCNN-TF2/logs\n",
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     2\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.75\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 2\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  1024\n",
            "IMAGE_META_SIZE                20\n",
            "IMAGE_MIN_DIM                  800\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [1024 1024    3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           footer_detector\n",
            "NUM_CLASSES                    8\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                200\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           200\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               50\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n",
            "Loading weights  /content/drive/MyDrive/Mask-RCNN-TF2/mask_rcnn_coco.h5\n",
            "manual annotation class count: 7\n",
            "annotations count:\t239\n",
            "manual annotation class count: 7\n",
            "annotations count:\t60\n",
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: //logdir//train/mask_rcnn_footer_detector_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py:49: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... can't pickle _thread.RLock objects\n",
            "Epoch 1/25\n",
            "  2/200 [..............................] - ETA: 1:34:10 - loss: 12.82952022-07-03 10:05:18.370700: E tensorflow/core/platform/default/device_tracer.cc:70] CUPTI error: CUPTI could not be loaded or symbol could not be found.\n",
            "200/200 [==============================] - 562s 3s/step - loss: 3.0332 - val_loss: 2.0170\n",
            "Epoch 2/25\n",
            "200/200 [==============================] - 409s 2s/step - loss: 2.1197 - val_loss: 2.4487\n",
            "Epoch 3/25\n",
            "200/200 [==============================] - 431s 2s/step - loss: 2.0181 - val_loss: 1.7486\n",
            "Epoch 4/25\n",
            "200/200 [==============================] - 435s 2s/step - loss: 1.8327 - val_loss: 1.9496\n",
            "Epoch 5/25\n",
            "200/200 [==============================] - 421s 2s/step - loss: 1.7259 - val_loss: 1.7653\n",
            "Epoch 6/25\n",
            "200/200 [==============================] - 426s 2s/step - loss: 1.7063 - val_loss: 1.1155\n",
            "Epoch 7/25\n",
            "200/200 [==============================] - 443s 2s/step - loss: 1.6171 - val_loss: 4.6709\n",
            "Epoch 8/25\n",
            "200/200 [==============================] - 421s 2s/step - loss: 1.6537 - val_loss: 1.6030\n",
            "Epoch 9/25\n",
            "200/200 [==============================] - 451s 2s/step - loss: 1.5900 - val_loss: 2.5352\n",
            "Epoch 10/25\n",
            "200/200 [==============================] - 410s 2s/step - loss: 1.5132 - val_loss: 1.3983\n",
            "Epoch 11/25\n",
            "200/200 [==============================] - 438s 2s/step - loss: 1.5542 - val_loss: 1.3530\n",
            "Epoch 12/25\n",
            "200/200 [==============================] - 429s 2s/step - loss: 1.4487 - val_loss: 1.8470\n",
            "Epoch 13/25\n",
            "200/200 [==============================] - 435s 2s/step - loss: 1.4088 - val_loss: 3.6046\n",
            "Epoch 14/25\n",
            "200/200 [==============================] - 405s 2s/step - loss: 1.3579 - val_loss: 2.4038\n",
            "Epoch 15/25\n",
            "200/200 [==============================] - 452s 2s/step - loss: 1.4968 - val_loss: 2.3224\n",
            "Epoch 16/25\n",
            "200/200 [==============================] - 420s 2s/step - loss: 1.4433 - val_loss: 2.4638\n",
            "Epoch 17/25\n",
            "200/200 [==============================] - 430s 2s/step - loss: 1.3866 - val_loss: 1.9647\n",
            "Epoch 18/25\n",
            "200/200 [==============================] - 423s 2s/step - loss: 1.3437 - val_loss: 2.1822\n",
            "Epoch 19/25\n",
            "200/200 [==============================] - 430s 2s/step - loss: 1.3935 - val_loss: 2.1228\n",
            "Epoch 20/25\n",
            "200/200 [==============================] - 425s 2s/step - loss: 1.3487 - val_loss: 1.3994\n",
            "Epoch 21/25\n",
            "200/200 [==============================] - 434s 2s/step - loss: 1.3261 - val_loss: 1.6353\n",
            "Epoch 22/25\n",
            "200/200 [==============================] - 413s 2s/step - loss: 1.2614 - val_loss: 3.0253\n",
            "Epoch 23/25\n",
            "200/200 [==============================] - 442s 2s/step - loss: 1.3481 - val_loss: 3.3915\n",
            "Epoch 24/25\n",
            "200/200 [==============================] - 429s 2s/step - loss: 1.2542 - val_loss: 3.1831\n",
            "Epoch 25/25\n",
            "200/200 [==============================] - 421s 2s/step - loss: 1.1773 - val_loss: 2.3374\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "footer_detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJ/IE0EJwHiCWCfmg2C/W9",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}